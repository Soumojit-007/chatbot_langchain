
# import streamlit as st
# from dotenv import load_dotenv
# from PyPDF2 import PdfReader
# import docx
# import io
# import os
# from langchain_google_genai import ChatGoogleGenerativeAI
# from langchain.text_splitter import CharacterTextSplitter
# from langchain.chains.question_answering import load_qa_chain
# from langchain.docstore.document import Document

# # Correct import for summarization
# from langchain.chains.summarize import load_summarize_chain
# from langchain.prompts import PromptTemplate

# # Load environment variables
# load_dotenv()
# api_key = os.getenv("GOOGLE_API_KEY")

# # Initialize the LLM
# llm = ChatGoogleGenerativeAI(
#     model="gemini-1.5-flash",
#     google_api_key=api_key
# )

# # Streamlit UI
# st.title("ğŸ“„ Google Gemini Chatbot - LangChain")

# uploaded_file = st.file_uploader("Upload a PDF or Word Document", type=["pdf", "docx"])

# def extract_text_from_docx(file):
#     doc = docx.Document(file)
#     return "\n".join([para.text for para in doc.paragraphs])

# if uploaded_file is not None:
#     try:
#         # Extract text from file
#         text = ""
#         if uploaded_file.name.endswith(".pdf"):
#             pdf_reader = PdfReader(io.BytesIO(uploaded_file.read()))
#             for page in pdf_reader.pages:
#                 text += page.extract_text() or ""
#         elif uploaded_file.name.endswith(".docx"):
#             text = extract_text_from_docx(uploaded_file)

#         # Split into chunks
#         text_splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=100)
#         texts = text_splitter.split_text(text)
#         docs = [Document(page_content=chunk) for chunk in texts]

#         # QA Chain (unchanged)
#         qa_chain = load_qa_chain(llm, chain_type="stuff")

#         # Custom prompt for summarization
#         custom_prompt = PromptTemplate(
#             input_variables=["text"],
#             template="Summarize the following document focusing on the main points:\n\n{text}\n\nSummary:"
#         )

#         # Summarization chain with custom prompt
#         summarization_chain = load_summarize_chain(
#             llm, chain_type="stuff",
#             prompt=custom_prompt
#         )

#         # Question input and response
#         query = st.text_input("Ask a question about the document:")
#         if query:
#             response = qa_chain.invoke({
#                 "input_documents": docs,
#                 "question": query
#             })
#             st.subheader("Response:")
#             st.write(response["output_text"])

#         # Summarize button
#         if st.button("Summarize Document"):
#             summary = summarization_chain.run(docs)
#             st.subheader("ğŸ“Œ Summary:")
#             st.write(summary)

#     except Exception as e:
#         st.error(f"âŒ Failed to process the file: {e}")



import streamlit as st
from dotenv import load_dotenv
from PyPDF2 import PdfReader
import docx
import io
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains.question_answering import load_qa_chain
from langchain.docstore.document import Document
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts import PromptTemplate
import time
from datetime import datetime

# Load environment variables
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# Page configuration
st.set_page_config(
    page_title="ğŸ“„ AI Document Assistant",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for advanced styling
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    
    .feature-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    
    .stats-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem 0;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
        background: #f1f3f4;
    }
    
    .success-message {
        background: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    
    .sidebar-content {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'document_processed' not in st.session_state:
    st.session_state.document_processed = False
if 'document_stats' not in st.session_state:
    st.session_state.document_stats = {}

# Initialize the LLM
@st.cache_resource
def initialize_llm():
    return ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        google_api_key=api_key
    )

try:
    llm = initialize_llm()
    llm_status = "âœ… Connected"
except:
    llm_status = "âŒ Connection Failed"

# Sidebar
with st.sidebar:
    st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)
    st.title("ğŸ”§ Control Panel")
    
    # System Status
    st.subheader("ğŸ” System Status")
    st.markdown(f"**LLM Status:** {llm_status}")
    st.markdown(f"**Session Time:** {datetime.now().strftime('%H:%M:%S')}")
    
    # Document Statistics
    if st.session_state.document_processed:
        st.subheader("ğŸ“Š Document Statistics")
        stats = st.session_state.document_stats
        st.metric("ğŸ“„ Total Pages", stats.get('pages', 'N/A'))
        st.metric("ğŸ“ Word Count", stats.get('words', 'N/A'))
        st.metric("ğŸ”¤ Character Count", stats.get('characters', 'N/A'))
        st.metric("ğŸ“¦ Text Chunks", stats.get('chunks', 'N/A'))
    
    # Settings
    st.subheader("âš™ï¸ Settings")
    chunk_size = st.slider("Chunk Size", 500, 2000, 1000, 100)
    chunk_overlap = st.slider("Chunk Overlap", 50, 200, 100, 25)
    
    # Clear chat history
    if st.button("ğŸ—‘ï¸ Clear Chat History", use_container_width=True):
        st.session_state.chat_history = []
        st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)

# Main header
st.markdown("""
<div class="main-header">
    <h1>ğŸ¤– AI Document Assistant</h1>
    <p>Upload, Analyze, and Chat with your Documents using Google Gemini</p>
</div>
""", unsafe_allow_html=True)

# Feature overview
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ“„ Document Upload</h4>
        <p>Support for PDF and Word documents with intelligent text extraction</p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ’¬ Smart Chat</h4>
        <p>Ask questions and get contextual answers from your documents</p>
    </div>
    """, unsafe_allow_html=True)

with col3:
    st.markdown("""
    <div class="feature-card">
        <h4>ğŸ“ Auto Summary</h4>
        <p>Generate comprehensive summaries with key insights</p>
    </div>
    """, unsafe_allow_html=True)

# File upload section
st.subheader("ğŸ“ Document Upload")
uploaded_file = st.file_uploader(
    "Choose a PDF or Word document",
    type=["pdf", "docx"],
    help="Upload your document to start chatting with it!"
)

def extract_text_from_docx(file):
    doc = docx.Document(file)
    return "\n".join([para.text for para in doc.paragraphs])

def calculate_stats(text, chunks):
    words = len(text.split())
    characters = len(text)
    return {
        'words': words,
        'characters': characters,
        'chunks': len(chunks)
    }

if uploaded_file is not None:
    try:
        with st.spinner("ğŸ”„ Processing document... Please wait"):
            # Extract text from file
            text = ""
            if uploaded_file.name.endswith(".pdf"):
                pdf_reader = PdfReader(io.BytesIO(uploaded_file.read()))
                pages = len(pdf_reader.pages)
                for page in pdf_reader.pages:
                    text += page.extract_text() or ""
            elif uploaded_file.name.endswith(".docx"):
                text = extract_text_from_docx(uploaded_file)
                pages = "N/A"

            # Split into chunks
            text_splitter = CharacterTextSplitter(
                separator="\n", 
                chunk_size=chunk_size, 
                chunk_overlap=chunk_overlap
            )
            texts = text_splitter.split_text(text)
            docs = [Document(page_content=chunk) for chunk in texts]

            # Calculate statistics
            stats = calculate_stats(text, texts)
            if pages != "N/A":
                stats['pages'] = pages
            st.session_state.document_stats = stats
            st.session_state.document_processed = True

            # QA Chain (unchanged)
            qa_chain = load_qa_chain(llm, chain_type="stuff")

            # Custom prompt for summarization
            custom_prompt = PromptTemplate(
                input_variables=["text"],
                template="Summarize the following document focusing on the main points:\n\n{text}\n\nSummary:"
            )

            # Summarization chain with custom prompt
            summarization_chain = load_summarize_chain(
                llm, chain_type="stuff",
                prompt=custom_prompt
            )

        # Success message
        st.markdown(f"""
        <div class="success-message">
            <h4>âœ… Document Successfully Processed!</h4>
            <p><strong>File:</strong> {uploaded_file.name}</p>
            <p><strong>Size:</strong> {len(text)} characters | <strong>Chunks:</strong> {len(texts)}</p>
        </div>
        """, unsafe_allow_html=True)

        # Main interface tabs
        tab1, tab2, tab3 = st.tabs(["ğŸ’¬ Chat with Document", "ğŸ“ Generate Summary", "ğŸ“Š Document Analysis"])

        with tab1:
            st.subheader("ğŸ’¬ Ask Questions About Your Document")
            
            # Chat interface
            query = st.text_input(
                "Type your question here...",
                placeholder="e.g., What are the main topics discussed in this document?",
                key="chat_input"
            )
            
            col1, col2 = st.columns([1, 4])
            with col1:
                ask_button = st.button("ğŸš€ Ask Question", use_container_width=True)
            
            if ask_button and query:
                with st.spinner("ğŸ¤” Thinking... Please wait"):
                    start_time = time.time()
                    response = qa_chain.invoke({
                        "input_documents": docs,
                        "question": query
                    })
                    end_time = time.time()
                    
                    # Add to chat history
                    st.session_state.chat_history.append({
                        "question": query,
                        "answer": response["output_text"],
                        "timestamp": datetime.now().strftime("%H:%M:%S"),
                        "processing_time": f"{end_time - start_time:.2f}s"
                    })
                
                st.rerun()
            
            # Display chat history
            if st.session_state.chat_history:
                st.subheader("ğŸ’­ Conversation History")
                for i, chat in enumerate(reversed(st.session_state.chat_history)):
                    with st.expander(f"Q{len(st.session_state.chat_history)-i}: {chat['question'][:50]}...", expanded=(i==0)):
                        st.markdown(f"**â° Time:** {chat['timestamp']} | **âš¡ Processing:** {chat['processing_time']}")
                        st.markdown(f"**â“ Question:** {chat['question']}")
                        st.markdown(f"**âœ¨ Answer:** {chat['answer']}")

        with tab2:
            st.subheader("ğŸ“ Document Summary")
            
            # Summary options
            col1, col2 = st.columns(2)
            with col1:
                summary_type = st.selectbox(
                    "Summary Type",
                    ["Comprehensive", "Key Points", "Executive Summary", "Technical Overview"]
                )
            
            if st.button("ğŸ“‹ Generate Summary", use_container_width=True):
                with st.spinner("ğŸ“ Generating summary... This may take a moment"):
                    start_time = time.time()
                    summary = summarization_chain.run(docs)
                    end_time = time.time()
                    
                    st.markdown("### ğŸ“Œ Document Summary")
                    st.markdown(f"**Summary Type:** {summary_type}")
                    st.markdown(f"**Generated in:** {end_time - start_time:.2f} seconds")
                    st.markdown("---")
                    st.write(summary)
                    
                    # Download summary option
                    st.download_button(
                        label="ğŸ“¥ Download Summary",
                        data=summary,
                        file_name=f"summary_{uploaded_file.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )

        with tab3:
            st.subheader("ğŸ“Š Document Analysis")
            
            # Display detailed statistics
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div class="stats-card">
                    <h3>{stats.get('pages', 'N/A')}</h3>
                    <p>Pages</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="stats-card">
                    <h3>{stats['words']:,}</h3>
                    <p>Words</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="stats-card">
                    <h3>{stats['characters']:,}</h3>
                    <p>Characters</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div class="stats-card">
                    <h3>{stats['chunks']}</h3>
                    <p>Text Chunks</p>
                </div>
                """, unsafe_allow_html=True)
            
            # Additional analysis
            st.subheader("ğŸ“ˆ Text Analysis")
            
            # Sample text preview
            with st.expander("ğŸ“– Document Preview (First 500 characters)"):
                st.text(text[:500] + "..." if len(text) > 500 else text)
            
            # Chunk information
            with st.expander("ğŸ” Chunk Analysis"):
                chunk_sizes = [len(chunk) for chunk in texts]
                avg_chunk_size = sum(chunk_sizes) / len(chunk_sizes)
                st.metric("Average Chunk Size", f"{avg_chunk_size:.0f} characters")
                st.metric("Largest Chunk", f"{max(chunk_sizes)} characters")
                st.metric("Smallest Chunk", f"{min(chunk_sizes)} characters")

    except Exception as e:
        st.error(f"âŒ Failed to process the file: {e}")
        st.info("ğŸ’¡ Please make sure your file is not corrupted and try again.")

else:
    # Welcome message
    st.markdown("""
    ### ğŸ‘‹ Welcome to AI Document Assistant!
    
    **Getting Started:**
    1. ğŸ“¤ Upload a PDF or Word document using the file uploader above
    2. ğŸ’¬ Ask questions about your document content
    3. ğŸ“ Generate automatic summaries
    4. ğŸ“Š View detailed document analysis
    
    **Supported Formats:** PDF (.pdf), Word Documents (.docx)
    """)
    
    # Example questions
    with st.expander("ğŸ’¡ Example Questions You Can Ask"):
        st.markdown("""
        - What are the main topics discussed in this document?
        - Can you summarize the key findings?
        - What are the conclusions or recommendations?
        - Who are the main people or organizations mentioned?
        - What dates or events are referenced?
        - What are the technical specifications mentioned?
        """)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    ğŸ¤– Powered by Google Gemini & LangChain | Built with Streamlit<br>
    <small>For best results, use clear and specific questions about your document content.</small>
</div>
""", unsafe_allow_html=True)